import
  Library/Data/SwitchCase
  Library/Data/Map
  Library/Data/Array
  Library/Data/Set/HashSet: 'HashSet'.

import
  gsl: [
    'SparseMatrix',
    'Vector'
  ]
  wordtree: 'WordTree'
.

#:language XFrozen

var Lexer is Object cnew: {
  collate => False.
  collateList => Nil.
  collateReg => Nil.
  fReg => String compileRegex: ?>s/[\[\]\{\}\/\?،\.,:;'"»«\!\@\#\$\%\^\&\*\(\)؟_\+=\-0987654321۰۹۸۷۶۵۴۳۲۱\`]|[\p{L}\p{N}\d-[\[\]\{\}\/\?،\.,:;'"i»«\!\@\#\$\%\^\&\*\(\)؟_\+=\-0987654321۰۹۸۷۶۵۴۳۲۱\`]]+/ $0 /gmuW<?.
  on: 'collate:' do: {:list
    my collate is True.
    my collateList is list.
    my collateReg is list copy fmap!: {\:x
        String compileRegex: 's/%s/%s/gmuW' % x.
    }.
  }.
  on: 'normalise:' do: {:&str
    str is my collateReg foldl: {:acc:x
      ^acc ~ x.
    } accumulator: str.
    ^str.
  }.
  on: 'split:' do: {:self:str
    my collate ifTrue: {
      str is self normalise: str.
    }.
    str is str replace: '\n' with: ' ', replace: '\t' with: ' '.
    str is str ~ my fReg.
    str is str reSplit: '\\s+'.#, filter: \:_:x x empty not.
    ^str.
  }.
  on: 'splitGen:' do: {:self:str
    my collate ifTrue: {
      str is self normalise: str.
    }.
    str is str ~ 's/\\s/ /g' ~ my fReg.
    ^str reSplitGen: '\\s+'.
  }.
}.

var puncReg is String compileRegex: ?>s/[‌‎\[\]\{\}،\/\?\.,:;'"»«\!\@\#\$\%\^\&\*\(\)؟_\+=\-\`\s*0-9۰-۹]//gmuW<?.
var isPunctuation is \:x (x ~ puncReg) empty.
var isStopword is \:ss:x ss contains: x.

var TokenAnalyser is Object cnew: {
  on: 'with:' do: {:lexer ^cnew: { lexer => lexer. }. }.

  on: 'analyse:' do: {:text
    var resmap is Map new.
    var stopwords is my stopwords is HashSet new addAll: (my lexer normalise: (File new: 'stopwords/persian', read), split: '\n').
    my lexer
      splitGen: text,
      each_v: {:x
        isStopword[stopwords, x] not & isPunctuation[x] not ifTrue: {
          (var &val is resmap at: x) isNil ifTrue: {
            resmap put: 1 at: x.
          } ifFalse: {
            val +=: 1.
          }.
        }.
      }.
    ^resmap.
  }.
  on: 'split:' do: {:text
    ^my lexer splitGen: text.
  }.
  on: 'isRemovalCandidate:' do: {:x
    isStopword[my stopwords, x] ifTrue: { ^True. }.
    isPunctuation[x] ifTrue: { ^True. }.
    ^False.
  }.

  on: 'spellcheckAndFix:withDictionaryTree:' do: {:str:tree
    # Pen writeln: 'sort for $$str'.
    var sugg is tree filterSorted: str.
    sugg count = 0 ifTrue: {
      ^[str, '<no suggestions>'].
    }.
    sugg head = str ifTrue: {
      ^[str, '<correct>'].
    }.
    ^[str, sugg from: 0 lengthMax: 3].
  }.

  on: 'spellcheck:withDictionaryTree:pre:post:' do: {:self:coll:tree:pre:post
    var i is 0.
    ^coll foldl: {:acc:str
      pre applyTo: (i +=: 1).
      post run.
      ^acc + (self split: str, fmap: {:str
        isPunctuation[str] ifTrue: { ^[str, '<correct>']. }.
        ^self spellcheckAndFix: str withDictionaryTree: tree.
      }, toArray).
    } accumulator: Array new.
  }.

  on: 'tag:pre:post:' do: {:text:pre:post
    var split is my lexer split: text. #, filter: \:_:x isStopword[x] not.

    var i is 0.
    ^split fmap!: {:tok
        pre[i +=: 1].
        tok containsPattern: '^[۰۹۸۷۶۵۴۳۲۱0987654321]+$', ifTrue: {
            post[i].
            ^[tok, 'num'].
        }.
        tok containsPattern: '^\\#$', ifTrue: {
            post[i].
            ^[tok, 'octothorp'].
        }.
        post[i].
        ^[tok, 'str'].
    }.
  }.
  on: 'tagPhrases:pre:post:' do: {:dtoks:pre:post
    frozen float-separators is ['.'].
    ^dtoks fmap: {:toks
        var state is \nothing.
        var tokbuf is Array new.
        var i is 0.
        var avail is toks count.
        var processed is Array new.
        var rejected is Nil.

        {^i < avail.} whileTrue: {
           var tok is toks at: i.

           var newstate is (frozen state-check is Object
            case: \nothing do: {
                ^(frozen top-check is String
                    case: 'str' do: {
                        tokbuf push: tok @ 0.
                        ^\accept.
                    },
                    case: 'num' do: {
                        tokbuf push: tok @ 0.
                        ^\int.
                    },
                    case: 'octothorp' do: {
                        tokbuf push: tok @ 0.
                        ^\hashtag0.
                    })
                switch: tok @ 1.
            },
            case: \int do: {
                ^(frozen num-check is String
                    case: 'str' do: {
                        float-separators contains: tok @ 0, ifTrue: {
                            tokbuf push: '.'.
                            ^\float.
                        } ifFalse: {
                            i -=: 1. # putback the token
                            ^\accept.
                        }.
                    },
                    case: 'num' do: {
                        tokbuf push: tok @ 0.
                        ^\int.
                    },
                    default: {
                        i -=: 1.
                        ^\accept.
                    })
                switch: tok @ 1.
            },
            case: \float do: {
                ^(frozen num-check is String
                    case: 'str' do: {
                        float-separators contains: tok @ 0, ifTrue: {
                            tok indexOf: '.', > 3 ifTrue: {
                                # not an IP address
                                i -=: 1.
                                ^\accept.
                            } ifFalse: {
                                (rejected = \ipaddr1) | (rejected = \ipaddr) ifTrue: {
                                    i -=: 1.
                                    ^\accept.
                                }.
                                tokbuf push: '.'.
                                ^\ipaddr.
                            }.
                        } ifFalse: {
                            i -=: 1. # putback the token
                            ^\accept.
                        }.
                    },
                    case: 'num' do: {
                        tokbuf push: tok @ 0.
                        ^\float.
                    },
                    default: {
                        i -=: 1.
                        ^\accept.
                    })
                switch: tok @ 1.
            },
            case: \hashtag0 do: {
                tokbuf push: tok @ 0.
                ^\hashtag1.
            },
            case: \hashtag1 do: {
                ^(frozen tag-check is String
                    case: 'str' do: {
                        tok @ 0 = '_' ifTrue: {
                            tokbuf push: tok @ 0.
                            ^\hashtag1.
                        } ifFalse: {
                            i -=: 1.
                            ^\accept.
                        }.
                    },
                    case: 'num' do: {
                        tokbuf push: tok @ 0.
                        ^\hashtag1.
                    },
                    default: {
                        i -=: 1.
                        ^\accept.
                    })
                switch: tok @ 1.
            },
            case: \ipaddr do: {
                # I . I . <here> [I . I]
                ^(frozen tag-check is String
                    case: 'str' do: {
                        tok @ 0 = '.' ifTrue: {
                            tokbuf push: tok @ 0.
                            ^\ipaddr1.
                        } ifFalse: {
                            i -=: tokbuf count.
                            ^\reject.
                        }.
                    },
                    case: 'num' do: {
                        rejected = \ipaddr ifTrue: {
                            i -=: tokbuf count.
                            ^\reject.
                        }.
                        tokbuf push: tok @ 0.
                        ^\ipaddr.
                    },
                    default: {
                        rejected = \ipaddr ifTrue: {
                            i -=: tokbuf count.
                            ^\reject.
                        }.
                        i -=: 1.
                        ^\accept.
                    })
                switch: tok @ 1.
            },
            case: \ipaddr1 do: {
                # I . I . I . <here> [I]
                ^(frozen tag-check is String
                    case: 'num' do: {
                        rejected = \ipaddr1 ifTrue: {
                            i -=: tokbuf count.
                            ^\reject.
                        }.
                        tokbuf push: tok @ 0.
                        ^\accept.
                    },
                    default: {
                        i -=: tokbuf count.
                        ^\reject.
                    })
                switch: tok @ 1.
            },
            default: {
                thisBlock error: 'unknown state $$state encountered'.
            }) switch: state.
            i +=: 1.
            newstate = \accept ifTrue: {
                processed push: [(tokbuf join: ''), (state toString skip: 1)].

                tokbuf is Array new.
                state is \nothing.
            } ifFalse: {
                newstate = \reject ifTrue: {

                    rejected is state.
                    state is \nothing.
                } ifFalse: {

                    state is newstate.
                }.
            }.
        }.
        ^processed.
    }.
}.

  on: 'TF-of:name:' do: {:from:name
      ^from copy fmap!: \:x x @ name.
  }.
  on: 'consolidateAll:pre:post:' do: {:self:allTargetTexts:pre:post
    var consolidated is Array new fill: allTargetTexts count with: \:_ Map new: \:_ 0.
    var allTokens is HashSet new.
    allTargetTexts each: {:i:targetText
      pre[i].
      self analyse: targetText last, each: {:k:v
        consolidated at: i, put: v at: k.
        allTokens add: k.
      }.
      post[i].
    }.
    ^Array < allTokens ; consolidated.
  }.
  on: 'consolidateAllWithLabels:pre:post:' do: {:self:allTargetTexts:pre:post
    var consolidated is Array new fill: allTargetTexts count with: \:_ Map new: \:_ 0.
    var allTokens is HashSet new.
    allTargetTexts each: {:i:targetText
      pre[i].
      var label is targetText head.
      self analyse: targetText last, each: {:k:v
        consolidated at: i, put: [label, v] at: k.
        allTokens add: k.
      }.
      post[i].
    }.
    ^[allTokens, consolidated].
  }.
  on: 'TFconsolidate:withTokens:pre:post:' do: {:self:consolidated:allTokens:pre:post
    var consolidateAll is Map new.
    var ii is 0.
    allTokens each_v: {:x
      pre[ii +=: 1].
      var tfsum is self
        TF-of: consolidated
        name: x,
        groupBy: \:x x head,
        fmap!: \:k:v v fmap!: \:x x last, sum.
      var cctfs is Map new.
      tfsum each: {:k:v
        cctfs put: v / tfsum count at: k.
      }.
      consolidateAll
        put: cctfs
        at: x.
      post[ii].
    }.
    ^consolidateAll.
  }.
  on: 'consolidate:pre:post:' do: {:self:allTargetTexts:pre:post
    my stopwords is HashSet new addAll: (my lexer normalise: (File new: 'stopwords/persian', read), split: '\n').
    var consolidateAll is HashMap new.
    var appearsIn is Map new.
    var ii is -1.
    var targetCount is allTargetTexts count.
    var defTokEntry is [(x = 0) toNumber,, (x: (Generator from: 0 to: targetCount + 1))].
    var tEstimate is 2.
    allTargetTexts each: {:idx:targetText
      idx mod: 5, ifFalse: {
        pre[idx].
        post[idx].
      }.
      var tIdx is idx + 1.
      var tArrIdx is Array new: tEstimate * 2, push: tIdx.
      self split: targetText last, each_v: {:tok
        self isRemovalCandidate: tok, continue. #50 - 90
        (var &tokEntry is consolidateAll at: tok) isNil ifTrue: {
          tokEntry is defTokEntry copy fmap!: \:x x.
          appearsIn put: tArrIdx copy at: tok.
          tokEntry @ tIdx +=: 1.
          tokEntry @ 1 +=: 1.
          consolidateAll put: tokEntry at: tok.
        } ifFalse: {
          tokEntry @ 0 +=: 1.
          (var &tokVal is tokEntry @ tIdx) ifFalse: {
            tokEntry @ 1 +=: 1.
            appearsIn @ tok push: tIdx.
            tEstimate +=: 1.
          }.
          tokVal +=: 1.
        }.
      }.
      tEstimate /=: 2.
    }.
    ^[consolidateAll, appearsIn].
  }.

  on: 'SWconsolidate:pre:post:' do: {:self:allTargetTexts:pre:post
    var ii is -1.
    var countv is allTargetTexts underlaying copy foldl: {:a:b ^a +=: 1.} accumulator: 0.
    var res is allTargetTexts withIndices foldl: {:acc:comp
      var &idx is comp head.
      var &targetText is comp last.
      var &consolidateAll is acc @ 0.
      var &DFconsAll is acc @ 1.
      var &appearsIn is acc @ 2.
      var &appearsInR is acc @ 3.
      var &tIdx is idx.
      var &newIdx is appearsIn count.
      pre[idx].
      self split: targetText, each_v: {:&tok
        # var idxI is Nil.
        # var t is Clock timeExecutionOf: {
        var idxI is appearsIn at: tok.
        # }.
        idxI isNil ifTrue: {
          idxI is newIdx.
          appearsIn put: idxI at: tok.
          appearsInR put: tok at: idxI.
          newIdx +=: 1.
          # Pen writeln: 'Miss $$t'.
        # } ifFalse: {
          # Pen writeln: 'Hit $$t'.
        }.
        consolidateAll
          incrementAtI: idxI
          andJ: tIdx
        .
        DFconsAll incrementAt: idxI.
      }.
      post[idx].
      ^acc.
    } accumulator: [SparseMatrix[1, countv], Vector[countv * 1000], HashMap new, HashMap new].
    ^res.
  }.

  on: 'calculateTF-IDF:withMap:pre:post:' do: {:consolidateAll:appearsIn:pre:post
    var ii is -1.
    consolidateAll each: {:k:v
      pre[ii +=: 1].
      post[ii].
      appearsIn at: k, each_v: {:i
        v @ i /=: v @ 1.
      }.
    }.
  }.


  on: 'calculateRSD:withMap:andDFVector:pre:post:' do: {:consolidateAll:tokenMap:DFconsAll:pre:post
    var ii is -1.
    # consolidateAll  <- (consolidateAll transpose * DFconsAll) transpose
    consolidateAll vectorMultiply: DFconsAll.
    # consolidateAll columns @rsd
    var vec is Vector[(var &size is consolidateAll size last)].
    var res is Array new fill: consolidateAll size head with: {:col
      pre[ii +=: 1].
      vec reset.
      consolidateAll column: col into: vec size: size.
      var &mean is gsl_stats_mean[vec vectorP, 1, size].
      var &sd   is gsl_stats_sd_m[vec vectorP, 1, size, mean].
      var &res  is sd / mean.
      post[ii].
      ^res.
    }.
    ^res.
  }.

  on: 'merge:tokens:pre:post:' do: {:self:consolidated:allTokens:pre:post
    var consolidateAll is Map new.
    var i is 0.
    allTokens each_v: {:x
      pre[(i +=: 1)].
      consolidateAll
        put:
            (self
              TF-of: consolidated
              name: x
            )
        at: x.
      post[i].
    }.
    ^consolidateAll.
  }.
  on: 'detectKeywords:forDocuments:pre:post:' do: {:consolidateAll:docs:pre:post
    var max-with-idx is {:what:vidx
      var idx is Array < '' ; '' ; '' ; '' ; ''.
      var max is Array < 0 ; 0 ; 0 ; 0 ; 0.
      what each: {:i:x
        x is x @ vidx.
        max each: {:iv:maxv
            x > maxv ifTrue: {
                idx put: i at: iv.
                max put: x at: iv.
                True break.
            }.
        }.
      }.
      ^[idx, max].
    }.
    var idx is -1.
    ^docs imap: {:i
      pre[idx +=: 1].
      var kw is max-with-idx[consolidateAll, i + 1].
      post[idx].
      ^kw.
    }.
  }.
  on: 'listKeywords:forKeywords:andDocuments:pre:post:' do: {:consolidateAll:keywords:docs:pre:post
    var idx is 0.
    ^docs fmap: {:i
      pre[idx +=: 1].
      var kw is keywords fmap: {:x
        var val is consolidateAll @ x.
        ^[x, val @ i].
      }.
      post[idx].
      ^kw.
    }.
  }.
  on: 'prettyPrint:tokens:' do: {:resmap:tokens
    var res is tokens
      fmap: \:k '%:L\t| %s' % [',\t', (resmap at: k), k],
      join: '\n'.
    var op is File tempFileLike: 'tmpXXXXXX', write: res.
    var op2 is File tempFileLike: 'tmpXXXXXX'.
    Shell call: 'sort -k${{(resmap at: tokens head) count}}$ ${{op path}}$ | tee ${{op2 path}}$'.
    var ff is op2 read.
    op close.
    op2 close.
    op delete.
    op2 delete.
    ^ff.
  }.
}.

# StdDev/mean
# with mean->0, this is really sensitive
Array on: 'relativeStandardDeviation' do: {
  var sums is Generator elementsOf: me, fmap: {\:x
    ^[x, x pow: 2].
  }, foldl: {\:acc:x
    ^[acc head + x head, acc last + x last].
  } accumulator: [0, 0].
  var mean is sums head / me count.
  var variance is (sums last / me count) - (mean * mean).
  ^variance sqrt / mean.
}.

Array on: 'asGenerator' do: {
  ^Generator elementsOf: me.
}.

Map on: 'merge:with:' do: {:self:other:blk
  other each: {:k:v
    self contains: k, ifTrue: {
      self put: blk[self @ k, v] at: k.
    } ifFalse: {
      self put: v at: k.
    }.
  }.
}.
Generator on: 'skip:' do: {:self:times
    times times: { self inext. }.
}.

# Interleaves two generators to run at the same pace~
Generator on: 'interleaveWith:' do: {:other
  ^me copy fmap: \:x [x, other next].
}.

Generator on: 'withIndices' do: {
  ^me imap: \:i:x [i, x].
}.

HashMap on: 'values' do: {
  var arr is Array new: me count.
  me each: {:_:v
    arr push: v.
  }.
  ^arr.
}.
